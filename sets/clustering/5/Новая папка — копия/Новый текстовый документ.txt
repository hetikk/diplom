МИНИСТЕРСТВО ОБРАЗОВАНИЯ И НАУКИ РОССИЙСКОЙ ФЕДЕРАЦИИ
ФГБОУ ВО “СЕВЕРО-КАВКАЗСКИЙ ГОРНО-МЕТАЛЛУРГИЧЕСКИЙ ИНСТИТУТ 
(ГОСУДАРСТВЕННЫЙ ТЕХНИЧЕСКИЙ УНИВЕРСИТЕТ)

Факультет		            Информационных технологий и электронной техники
Кафедра	                   	Информатика и вычислительная техника
Направление подготовки	Информатика и вычислительная техника
Профиль			АСУ


ПОЯСНИТЕЛЬНАЯ ЗАПИСКА
К ВЫПУСКНОЙ КВАЛИФИКАЦИОННОЙ РАБОТЕ

на тему: Разработка системы кластеризации документов на базе методов машинного обучения.



Студент                                                            	    Кастуев Хетаг Асланович
Руководитель проекта	                                                             Будаева А.А.



Проект рассмотрен кафедрой и допущен к защите в ГЭК

Заведующий кафедрой                                                         проф. Гроппен В. О.



г. Владикавказ 2020 г.
Реферат
Пояснительная записка 100 с., 13 рис., 12 табл., 8 ист., 2 прил.
Кластеризация, документ, корпус, блок.

Объект разработки: системы кластеризации документов на базе методов машинного обучения.

Цель выпускной работы: создание ПП, способного кластеризовывать документы. 

Использованное прикладное и системное программное обеспечение:
Операционная система Windows 10 PRO – 64 bit.
Среда разработки IntelliJ IDEA.

Характеристики вычислительной системы:
AMD Ryzen 5 3600 6-Core Procesor 3.6 (4,2) ГГц 
NVIDIA GeForce RTX 2060 6GB
ОЗУ 16Гб

Полученные результаты:
<…>

 
Оглавление
Реферат	2
Введение	5
Цели кластеризации	5
Применение	6
Биология и биоинформатика	6
Медицина	6
Маркетинг	7
Интернет	7
Компьютерные науки	7
Глава 1. Аналитический обзор	8
1.1.	Постановка задачи	8
1.2.	Кластеризация документов	8
1.3.	Мера расстояний	9
1.3.1.	Евклидово расстояние	9
1.3.2.	Квадрат евклидова расстояния	9
1.3.3.	Расстояние городских кварталов	10
1.3.4.	Расстояние Чебышева	10
1.3.5.	Степенное расстояние	10
1.4.	Алгоритмы классификации	11
1.4.1.	Алгоритмы иерархической кластеризации;	11
1.4.2.	Алгоритмы иерархической кластеризации	11
1.4.3.	Нечеткие алгоритмы	12
1.4.4.	Алгоритмы, основанные на теории графов	13
1.4.5.	Алгоритм выделения связных компонент	13
1.4.6.	Алгоритм минимального покрывающего дерева	14
1.4.7.	Послойная кластеризация	15
Список использованных источников	16

Введение
Кластерный анализ — задача разбиения заданной выборки объектов (ситуаций) на непересекающиеся подмножества, называемые кластерами, так, чтобы каждый кластер состоял из схожих объектов, а объекты разных кластеров существенно отличались. Задача кластеризации относится к статистической обработке, а также к широкому классу задач обучения без учителя.
 
Цели кластеризации
	Понимание данных путём выявления кластерной структуры. Разбиение выборки на группы схожих объектов позволяет упростить дальнейшую обработку данных и принятия решений, применяя к каждому кластеру свой метод анализа (стратегия «разделяй и властвуй»).
	Сжатие данных. Если исходная выборка избыточно большая, то можно сократить её, оставив по одному наиболее типичному представителю от каждого кластера.
	Обнаружение новизны. Выделяются нетипичные объекты, которые не удаётся присоединить ни к одному из кластеров.
В первом случае число кластеров стараются сделать поменьше. Во втором случае важнее обеспечить высокую степень сходства объектов внутри каждого кластера, а кластеров может быть сколько угодно. В третьем случае наибольший интерес представляют отдельные объекты, не вписывающиеся ни в один из кластеров.
Во всех этих случаях может применяться иерархическая кластеризация, когда крупные кластеры дробятся на более мелкие, те в свою очередь дробятся ещё мельче, и т. д. Такие задачи называются задачами таксономии.
Результатом таксономии является древообразная иерархическая структура. При этом каждый объект характеризуется перечислением всех кластеров, которым он принадлежит, обычно от крупного к мелкому.

Классическим примером таксономии на основе сходства является биноминальная номенклатура живых существ, предложенная Карлом Линнеем в середине XVIII века. Аналогичные систематизации строятся во многих областях знания, чтобы упорядочить информацию о большом количестве объектов.

Применение
Биология и биоинформатика
	В области экологии кластеризация используется для выделения пространственных и временных сообществ организмов в однородных условиях;
	Кластерный анализ используется для группировки схожих геномных последовательностей в семейство генов, которые являются консервативными структурами для многих организмов и могут выполнять схожие функции; 
	Кластеризация помогает автоматически определять генотипы по различным частям хромосом;
	Алгоритмы применяются для выделения небольшого числа групп генетических вариации человеческого генома.
Медицина
	Используется в позитронно-эмиссионной томографии для автоматического выделения различных типов тканей на трехмерном изображении;
	Применяется для выявления шаблонов устойчивости к антибиотикам; для классификации антибиотиков по типу антибактериальной активности.

Маркетинг
	Кластеризация широко используется при изучении рынка для обработки данных, полученных из различных опросов. Может применяться для выделения типичных групп покупателей, разделения рынка для создания персонализированных предложений, разработки новых линий продукции.
Интернет
	Выделение групп людей на основе графа связей в социальных сетях;
	Повышение релевантности ответов на поисковые запросы путем группировки веб-сайтов по смысловым значениям поискового запроса.
Компьютерные науки
	Кластеризация используется в сегментации изображений для определения границ и распознавания объектов;
	Кластерный анализ применяется для определения образовавшихся популяционных ниш в ходе работы эволюционных алгоритмов для улучшения параметров эволюции;
	Подбор рекомендаций для пользователя на основе предпочтений других пользователей в данном кластере;
	Определение аномалий путем построения кластеров и выявления неклассифицированных объектов.
Глава 1. Аналитический обзор
	Постановка задачи
Целью моей дипломной работы является создание ПП, способного кластеризовать различные документы.
Исходя из поставленной цели, были выделены следующие задачи:
	Провести аналитический обзор предметной области.
	Выбрать математическую модель
	Создать программный комплекс, реализующий разработанный алгоритм.
	Фактически разработанный программный комплекс.
	Кластеризация документов
Кластеризация (или кластерный анализ) — это задача разбиения множества объектов на группы, называемые кластерами. Внутри каждой группы должны оказаться «похожие» объекты, а объекты разных группы должны быть как можно более отличны. Главное отличие кластеризации от классификации состоит в том, что перечень групп четко не задан и определяется в процессе работы алгоритма.

Применение кластерного анализа в общем виде сводится к следующим этапам:
	Отбор выборки объектов для кластеризации.
	Определение множества переменных, по которым будут оцениваться объекты в выборке. При необходимости – нормализация значений переменных.
	Вычисление значений меры сходства между объектами.
	Применение метода кластерного анализа для создания групп сходных объектов (кластеров).
	Представление результатов анализа.

После получения и анализа результатов возможна корректировка выбранной метрики и метода кластеризации до получения оптимального результата.

	Мера расстояний
Итак, как же определять «похожесть» объектов? Для начала нужно составить вектор характеристик для каждого объекта — как правило, это набор числовых значений, например, рост-вес человека. Однако существуют также алгоритмы, работающие с качественными (т.н. категорийными) характеристиками.

После того, как мы определили вектор характеристик, можно провести нормализацию, чтобы все компоненты давали одинаковый вклад при расчете «расстояния». В процессе нормализации все значения приводятся к некоторому диапазону, например, [-1, -1] или [0, 1].

Наконец, для каждой пары объектов измеряется «расстояние» между ними — степень похожести.

	Евклидово расстояние
Наиболее распространенная функция расстояния. Представляет собой геометрическим расстоянием в многомерном пространстве: 
p(x,x')=√(∑_i^n▒(x_i-x_i^' )^2 )

	Квадрат евклидова расстояния
Применяется для придания большего веса более отдаленным друг от друга объектам. Это расстояние вычисляется следующим образом:
p(x,x')=∑_i^n▒〖(x_i-x_i^')〗^2 

	Расстояние городских кварталов
Это расстояние является средним разностей по координатам. В большинстве случаев эта мера расстояния приводит к таким же результатам, как и для обычного расстояния Евклида. Однако для этой меры влияние отдельных больших разностей (выбросов) уменьшается (т.к. они не возводятся в квадрат). Формула для расчета манхэттенского расстояния:
p(x,x')=∑_i^n▒|x_i-x_i^' | 

	Расстояние Чебышева
Это расстояние может оказаться полезным, когда нужно определить два объекта как «различные», если они различаются по какой-либо одной координате. Расстояние Чебышева вычисляется по формуле:
p(x,x')=max⁡(|x_i-x_i^' |)

	Степенное расстояние
Применяется в случае, когда необходимо увеличить или уменьшить вес, относящийся к размерности, для которой соответствующие объекты сильно отличаются. Степенное расстояние вычисляется по следующей формуле:
p(x,x')=r√(∑_i^n▒(x_i-x_i^' )^p )
где r и p – параметры, определяемые пользователем. Параметр p ответственен за постепенное взвешивание разностей по отдельным координатам, параметр r ответственен за прогрессивное взвешивание больших расстояний между объектами. Если оба параметра – r и p — равны двум, то это расстояние совпадает с расстоянием Евклида.

	Алгоритмы классификации
	Алгоритмы иерархической кластеризации; 
Среди алгоритмов иерархической кластеризации выделяются два основных типа: восходящие и нисходящие алгоритмы. Нисходящие алгоритмы работают по принципу «сверху-вниз»: в начале все объекты помещаются в один кластер, который затем разбивается на все более мелкие кластеры. Более распространены восходящие алгоритмы, которые в начале работы помещают каждый объект в отдельный кластер, а затем объединяют кластеры во все более крупные, пока все объекты выборки не будут содержаться в одном кластере. Таким образом строится система вложенных разбиений. Результаты таких алгоритмов обычно представляют в виде дерева – дендрограммы. Классический пример такого дерева – классификация животных и растений.

Для вычисления расстояний между кластерами чаще все пользуются двумя расстояниями: одиночной связью или полной связью (см. обзор мер расстояний между кластерами).

К недостатку иерархических алгоритмов можно отнести систему полных разбиений, которая может являться излишней в контексте решаемой задачи.

	Алгоритмы иерархической кластеризации
Задачу кластеризации можно рассматривать как построение оптимального разбиения объектов на группы. При этом оптимальность может быть определена как требование минимизации среднеквадратической ошибки разбиения:
e^2 (X,L)=∑_(j=1)^K▒∑_(i=1)^(n_j)▒‖x_i^((j) )-c_j ‖^2 
где cj — «центр масс» кластера j (точка со средними значениями характеристик для данного кластера).

Алгоритмы квадратичной ошибки относятся к типу плоских алгоритмов. Самым распространенным алгоритмом этой категории является метод k-средних. Этот алгоритм строит заданное число кластеров, расположенных как можно дальше друг от друга. Работа алгоритма делится на несколько этапов:
	Случайно выбрать k точек, являющихся начальными «центрами масс» кластеров.
	Отнести каждый объект к кластеру с ближайшим «центром масс».
	Пересчитать «центры масс» кластеров согласно их текущему составу.
	Если критерий остановки алгоритма не удовлетворен, вернуться к п. 2.

В качестве критерия остановки работы алгоритма обычно выбирают минимальное изменение среднеквадратической ошибки. Так же возможно останавливать работу алгоритма, если на шаге 2 не было объектов, переместившихся из кластера в кластер.

К недостаткам данного алгоритма можно отнести необходимость задавать количество кластеров для разбиения.
	Нечеткие алгоритмы
Наиболее популярным алгоритмом нечеткой кластеризации является алгоритм c-средних (c-means). Он представляет собой модификацию метода k-средних. Шаги работы алгоритма:

	Выбрать начальное нечеткое разбиение n объектов на k кластеров путем выбора матрицы принадлежности U размера n x k.
	Используя матрицу U, найти значение критерия нечеткой ошибки:
 ,
где ck — «центр масс» нечеткого кластера k:
 .
	Перегруппировать объекты с целью уменьшения этого значения критерия нечеткой ошибки.
	Возвращаться в п. 2 до тех пор, пока изменения матрицы U не станут незначительными.
Этот алгоритм может не подойти, если заранее неизвестно число кластеров, либо необходимо однозначно отнести каждый объект к одному кластеру.
	Алгоритмы, основанные на теории графов 
Суть таких алгоритмов заключается в том, что выборка объектов представляется в виде графа G=(V, E), вершинам которого соответствуют объекты, а ребра имеют вес, равный «расстоянию» между объектами. Достоинством графовых алгоритмов кластеризации являются наглядность, относительная простота реализации и возможность вносения различных усовершенствований, основанные на геометрических соображениях. Основными алгоритмам являются алгоритм выделения связных компонент, алгоритм построения минимального покрывающего (остовного) дерева и алгоритм послойной кластеризации.

	Алгоритм выделения связных компонент
В алгоритме выделения связных компонент задается входной параметр R и в графе удаляются все ребра, для которых «расстояния» больше R. Соединенными остаются только наиболее близкие пары объектов. Смысл алгоритма заключается в том, чтобы подобрать такое значение R, лежащее в диапазон всех «расстояний», при котором граф «развалится» на несколько связных компонент. Полученные компоненты и есть кластеры.

Для подбора параметра R обычно строится гистограмма распределений попарных расстояний. В задачах с хорошо выраженной кластерной структурой данных на гистограмме будет два пика – один соответствует внутрикластерным расстояниям, второй – межкластерным расстояния. Параметр R подбирается из зоны минимума между этими пиками. При этом управлять количеством кластеров при помощи порога расстояния довольно затруднительно.

	Алгоритм минимального покрывающего дерева
Алгоритм минимального покрывающего дерева сначала строит на графе минимальное покрывающее дерево, а затем последовательно удаляет ребра с наибольшим весом. На рисунке изображено минимальное покрывающее дерево, полученное для девяти объектов.

 

Путём удаления связи, помеченной CD, с длиной равной 6 единицам (ребро с максимальным расстоянием), получаем два кластера: {A, B, C} и {D, E, F, G, H, I}. Второй кластер в дальнейшем может быть разделён ещё на два кластера путём удаления ребра EF, которое имеет длину, равную 4,5 единицам.

	Послойная кластеризация
Алгоритм послойной кластеризации основан на выделении связных компонент графа на некотором уровне расстояний между объектами (вершинами). Уровень расстояния задается порогом расстояния c. Например, если расстояние между объектами  , то  .

Алгоритм послойной кластеризации формирует последовательность подграфов графа G, которые отражают иерархические связи между кластерами:

 ,

где Gt = (V, Et) — граф на уровне сt,
 ,
сt – t-ый порог расстояния,
m – количество уровней иерархии,
G0 = (V, o), o – пустое множество ребер графа, получаемое при t0 = 1,
Gm = G, то есть граф объектов без ограничений на расстояние (длину ребер графа), поскольку tm = 1.

Посредством изменения порогов расстояния {с0, …, сm}, 
где 0 = с0 < с1 < …< сm = 1, возможно контролировать глубину иерархии получаемых кластеров. Таким образом, алгоритм послойной кластеризации способен создавать как плоское разбиение данных, так и иерархическое.
 
Список использованных источников
http://www.online-decoder.com/ru (декодер)
https://habr.com/ru/post/101338 
