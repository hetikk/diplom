Почему машинному обучению с трудом дается причинно-следственная связь?
Автор оригинала: Ben Dickson
Блог компании OTUS,
Машинное обучение
Перевод

Эта статья является частью наших обзоров исследовательских работ в области ИИ, серии публикаций, в которых исследуются последние открытия в области искусственного интеллекта.

Просматривая следующую короткую видеопоследовательность, вы естественным образом можете сделать выводы о причинно-следственных связях между различными элементами в ней. Например, вы можете наблюдать, как бита и рука бейсболиста движутся в унисон, и вы знаете, что именно рука игрока вызывает движение биты, а не наоборот. Вам также не нужно объяснять, что это бита вызывает резкое изменение траектории мяча.

Точно так же вы можете представить альтернативные сценарии, например, что произошло бы, если бы мяч пролетел немного выше и не попал в биту.


Такие выводы приходят к нам, людям, интуитивно. Мы обучаемся им в очень раннем возрасте без явных указаний от кого-либо, просто наблюдая за миром. Но для алгоритмов машинного обучения, которым удалось превзойти людей в таких сложных задачах, как го и шахматы, причинно-следственная связь (причинность или каузальность от causality ) до сих пор остается сложной задачей. Алгоритмы машинного обучения, особенно глубокие нейронные сети, очень хороши в выявлении тонких закономерностей в огромных наборах данных. Они могут преобразовывать звук в реальном времени, размечать тысячи изображений и видеокадров в секунду, а также проверять рентгеновские снимки и МРТ на предмет наличия злокачественных образований. Но им сложно делать простые причинно-следственные выводы, подобные тем, которые мы только что продемонстрировали на примере видео про бейсбол.

В статье под названием «К обучению каузальных представлений» исследователи из Института интеллектуальных систем Макса Планка, Монреальского института алгоритмов обучения (Mila) и Google Research обсуждают проблемы, возникающие из-за отсутствия каузальных представлений в моделях машинного обучения и предоставляют инструкции по созданию систем искусственного интеллекта, которые способные обучать каузальные представления.

Это одна из нескольких попыток, направленных на изучение и решение проблемы отсутствия внятной причинно-следственной методологии в машинном обучении, которая может стать ключом к преодолению некоторых из основных проблем, с которыми сегодня сталкивается эта область.

Независимые и одинаково распределенные данные
Почему модели машинного обучения не имеют успеха в генерализации за рамки своих узких областей и обучающих данных?

«Машинное обучение часто игнорирует информацию, которую живые организмы активно используют: вмешательство в окружающий мир, сдвиги предметной области, временные структуры - в целом, мы считаем эти факторы помехой и пытаемся устранить их», - пишут авторы статьи о каузальной репрезентации. «В дополнение к этому, большинство текущих успехов машинного обучения сводятся к крупномасштабному распознаванию образов на надлежащим образом собранных независимых и идентично распределенных данных (i.i.d. - independent and identically distributed data)».

iid - это термин, часто используемый в машинном обучении. Он предполагает, что случайные наблюдения в предметной области не зависят друг от друга и имеют постоянную вероятность возникновения. Простейший пример iid - это подбрасывание монеты или броски кубика. Результат каждого нового броска не зависит от предыдущих, и вероятность каждого результата остается постоянной.

Когда дело доходит до более сложных областей, таких как компьютерное зрение, инженеры по разработке алгоритмов машинного обучения пытаются максимально приблизить предметную область задачи к iid, обучая модель на очень больших массивах примеров. Предполагается, что при наличии достаточного количества примеров модель машинного обучения способна выразить общее распределение задачи в своих параметрах. Но в реальном мире распределения часто изменчивы из-за факторов, которые нельзя учитывать и контролировать в обучающих данных. Например, сверточные нейронные сети, обученные на миллионах изображений, могут давать неправильные результаты, когда они видят объекты в новых условиях освещения, под немного другими углами или на новом фоне.

Объекты в обучающих наборах данных по сравнению с объектами в реальном мире (источник: objectnet.dev).
Объекты в обучающих наборах данных по сравнению с объектами в реальном мире (источник: objectnet.dev).
Попытки решить эти проблемы в основном заключаются в обучении моделей машинного обучения на большем количестве примеров. Но по мере того, как среда становится все более сложной, становится невозможным охватить все распределение посредством добавления большего количества обучающих примеров. Это особенно заметно в тех областях, где агенты ИИ должны взаимодействовать с миром, например в робототехнике и беспилотных автомобилях. Из-за отсутствия понимания причинно-следственных связей очень сложно делать прогнозы и успешно справляться в новых обстоятельствах. Вот почему вы до сих пор видите, как беспилотные автомобили совершают странные и опасные ошибки даже после того, как они прошли миллионы миль тренировок.


«Для генерализации за пределы iid-сетапа требуется изучение не просто статистических ассоциаций между переменными, но и лежащей в основе причинно-следственной (каузальной) модели», - пишут исследователи ИИ.

Каузальные модели также позволяют людям использовать ранее полученные знания в новых областях. Например, когда вы изучаете стратегию в реальном времени (RTS), такую ​​как Warcraft, вы можете быстро применить свои знания в других подобных играх StarCraft и Age of Empires. Однако трансферное обучение в алгоритмах машинного обучения ограничивается очень поверхностными применениями, такими как точная донастройка классификатора изображений для обнаружения новых типов объектов. В более сложных задачах, таких как обучение видеоиграм, модели машинного обучения нуждаются в огромном объеме обучения (тысячам игровых лет) и крайне плохо реагируют на незначительные изменения в среде (например, игра на новой карте или с небольшими изменениями в правилах).

«Таким образом, при изучении каузальной модели требуется меньше примеров для адаптации, поскольку большая часть знаний, то есть модули, можно повторно использовать без дальнейшего обучения», - пишут авторы статьи о каузальном машинном обучении.

Каузальное обучение

Итак, почему iid остается доминирующей формой машинного обучения, несмотря на его известные недостатки? Подходы, основанные чисто на наблюдении, масштабируемы. Вы можете продолжать повышать точность, добавляя больше обучающих данных, и вы можете ускорить процесс обучения, добавив больше вычислительной мощности. Фактически, одним из ключевых факторов недавнего успеха глубокого обучения является доступность большего количества данных и более мощные процессоры.

Модели на основе iid также легко оценивать: возьмите большой набор данных, разделите его на обучающие и тестовые наборы, обучите модель на обучающих данных и проверьте ее производительность, измерив точность ее прогнозов на тестовом наборе. Продолжайте обучение, пока не достигнете требуемой точности. Уже существует множество общедоступных наборов данных, которые предоставляют такие тесты, например ImageNet, CIFAR-10 и MNIST. Существуют также наборы данных для конкретных задач, такие как набор данных COVIDx для диагностики covid-19 и набор данных для диагностики рака молочной железы из Висконсина (Wisconsin Breast Cancer Diagnosis). Во всех случаях задача одна и та же: разработать модель машинного обучения, которая может предсказывать результаты на основе статистических закономерностей.

Но, как отмечают исследователи ИИ в своей статье, точных прогнозов часто недостаточно для принятия обоснованных решений. Например, во время пандемии коронавируса многие системы машинного обучения начали давать сбои, потому что они были обучены статистическим закономерностям, а не причинно-следственным связям. По мере изменения образа жизни точность моделей падала.

Каузальные модели остаются устойчивыми, когда какие-либо вмешательства изменяют статистическое распределение задачи. Например, когда вы впервые видите объект, ваш разум подсознательно исключит освещение из его внешнего вида. Вот почему, как правило, вы можете распознать объект, когда видите его под другим освещением.

Каузальные модели также позволяют нам реагировать на ситуации, которые мы не видели раньше, и рассуждать об альтернативных сценариях (counterfactuals). Нам не нужно сгонять машину со скалы, чтобы понимать, что произойдет. Альтернативные сценарии играют важную роль в сокращении количества обучающих примеров, необходимых для модели машинного обучения.

Причинно-следственная связь также может иметь решающее значение для борьбы с состязательными атаками (adversarial attacks), тонкими манипуляциями, которые вынуждают системы машинного обучения давать самые неожиданные сбои. «Эти атаки явно представляют собой нарушение предположения iid, лежащего в основе статистического машинного обучения», - пишут авторы статьи, добавляя, что состязательные уязвимости являются доказательством различий в механизмах устойчивости человеческого интеллекта и алгоритмов машинного обучения. Исследователи также предполагают, что причинно-следственная связь может быть возможной защитой от состязательных атак.

Состязательные атаки нацелены на чувствительность машинного обучения к iid. На этом изображении добавление незаметного слоя шума к изображению панды заставляет сверточную нейронную сеть принимать его за гиббона.
Состязательные атаки нацелены на чувствительность машинного обучения к iid. На этом изображении добавление незаметного слоя шума к изображению панды заставляет сверточную нейронную сеть принимать его за гиббона.
В широком смысле причинно-следственная связь может решить проблему отсутствия генерализации в машинном обучении. «Будет справедливо сказать, что большая часть текущей практики (решения задач эталонного iid тестирования) и большинство теоретических результатов (о генерализации в iid-сетапах) не решают в строгом понимании до сих пор открытую задачу генерелизации», - пишут исследователи.

Добавление причинно-следственной связи в машинное обучение
В своей статье исследователи ИИ объединяют несколько концепций и принципов, которые могут иметь важное значение для создания каузальных моделей машинного обучения.

Две из этих концепций включают «структурные каузальные модели» и «независимые каузальные механизмы». В целом, принципы гласят, что вместо поиска поверхностных статистических корреляций система ИИ должна иметь возможность идентифицировать каузальные переменные и разделять их влияние на среду.

Это механизм, который позволяет обнаруживать различные объекты независимо от угла обзора, фона, освещения и других шумов. Разделение этих каузальных переменных сделает системы ИИ более устойчивыми к непредсказуемым изменениям и вмешательствам. В результате у каузальных моделей ИИ не будет потребности в огромных наборах обучающих данных.

«Как только каузальная модель становится доступной на основе внешнего человеческого знания или процесса обучения, причинное осмысление позволяет делать выводы о влиянии вмешательств, альтернативных сценариях и ​​потенциальных результатах», - пишут авторы статьи о каузальном машинном обучении.

Авторы также исследуют, как эти концепции могут быть применены к различным отраслям машинного обучения, включая обучение с подкреплением, которое имеет решающее значение для задач, в которых интеллектуальный агент во многом полагается на исследование среды и поиск решений путем проб и ошибок. Причинные структуры могут помочь сделать обучение с подкреплением более эффективным, позволяя принимать обоснованные решения с самого начала обучения вместо случайных и иррациональных действий.

Исследователи предлагают идеи для систем искусственного интеллекта, которые сочетают механизмы машинного обучения и структурные каузальные модели (SCM): «Чтобы объединить структурное каузальное моделирование и обучение представлениям, мы должны стремиться встроить SCM в более крупные модели машинного обучения, входные и выходные данные которых могут быть многомерными и неструктурированными, но внутренняя работа которых, по крайней мере, частично регулируется SCM (которая может быть параметризована с помощью нейронной сети). Результатом может стать модульная архитектура, в которой различные модули можно индивидуально настраивать и повторно использовать для новых задач».

Такие концепции приближают нас к модульному подходу, который использует человеческий разум (по крайней мере, насколько нам известно) для связывания и повторного использования знаний и навыков в различных сферах и областях мозга.

Сочетание каузальных графов с машинным обучением позволит агентам ИИ создавать модули, которые можно применять к различным задачам без длительного обучения.
Сочетание каузальных графов с машинным обучением позволит агентам ИИ создавать модули, которые можно применять к различным задачам без длительного обучения.
Однако стоит отметить, что идеи, представленные в статье, находятся на концептуальном уровне. Как признают авторы, реализация этих концепций сталкивается с рядом проблем: «(а) во многих случаях нам необходимо вычленить абстрактные каузальные переменные из доступных низкоуровневых входных признаков; (б) нет единого мнения о том, какие аспекты данных раскрывают причинно-следственные связи; (c) обычного экспериментального протокола обучения и набора тестов может быть недостаточно для вывода и оценки причинно-следственных связей на существующих наборах данных, и нам может потребоваться создать новые критерии, например, с доступом к информации о среде и вмешательствах; (d) даже в тех ограниченных случаях, которые мы понимаем, нам часто не хватает масштабируемых и численно обоснованных алгоритмов».

Но что интересно, исследователи черпают вдохновение большого количества независимых исследований, проводимых в этой области. В статье содержатся ссылки на работу, проделанную Джудеей Перл, ученым, удостоенным премии Тьюринга, наиболее известной своей работой по причинному выводу. Перл является ярым критиком чистых методов глубокого обучения. Между тем Йошуа Бенжио, один из соавторов статьи и еще один обладатель премии Тьюринга, является одним из пионеров глубокого обучения.

В статье также содержится несколько идей, которые частично совпадают с идеей гибридных моделей искусственного интеллекта, предложенной Гэри Маркусом, которая сочетает в себе логическую силу символических систем с возможностями распознавания образов нейронных сетей. Однако в статье нет прямых ссылок на гибридные системы.

Эта статья также соответствует концепции второй системы глубокого обучения, впервые предложенной Bengio в ходе выступления на конференции NeurIPS 2019 AI. Идея второй системы глубокого обучения заключается в создании типа архитектуры нейронной сети, которая может изучать более высокие представления данных. Высшие представления имеют решающее значение для причинно-следственной связи, рассуждений и трансферного обучения.

Хотя неясно, какой из нескольких предложенных подходов поможет решить проблему каузального машинного обучения, тот факт, что идеи из разных - и часто противоречащих друг другу - школ мысли объединяются, гарантированно дает интересные результаты.

«По своей сути iid распознавание образов - это всего лишь математическая абстракция, и каузальность может иметь важное значение для большинства форм живого обучения», - пишут авторы. «До сих пор машинное обучение игнорировало полную интеграцию каузальности, и в этой статье утверждается, что интеграция каузальных понятий принесет ощутимую пользу».